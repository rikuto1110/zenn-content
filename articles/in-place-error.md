---
title: "PyTorch ã¨ in-place operation ã®ã‚¨ãƒ©ãƒ¼"
emoji: "ğŸŒ"
type: "tech" # tech æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["python", "PyTorch"]
published: true
---

# æœ¬è¨˜äº‹ã§ä¼ãˆãŸã„ã“ã¨
- PyTorchã§ `RuntimeError: a view of a leaf Variable that requires grad is being used in an in-place operation.` ã¨ã„ã† Error ãŒå‡ºãŸã‚‰ã€in-place operationãŒåŸå› ã€‚
- in-place operation ã¨ã¯ã€`x.add_()` , `x += 0.5` , `x[mask] = 0.5` ã®ã‚ˆã†ãªãƒ†ãƒ³ã‚½ãƒ«ã®å€¤ã‚’ç›´æ¥æ›¸ãæ›ãˆã‚‹æ¼”ç®—ã€‚
- ä¸Šè¨˜ã®Errorã¯ä»¥ä¸‹ã®æ–¹æ³•ã§è§£æ±º

  - `x.add_()` ã¯ `x = x.add()`ã¨ã™ã‚‹ã€‚

  - `x += 1` ã¯ `x = x + 1` ã¨ã™ã‚‹ã€‚

  - mask ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€ä¾‹ãˆã°ä¸‹ã®å¼ã«ç¤ºã™ã‚ˆã†ã«$a$ ã¨ $b$ ã‚’æ–°ã—ã„å€¤ $a'$ ã¨ $b'$ ã§ç½®ãæ›ãˆãŸã„å ´åˆã€å¤‰æ›´å¾Œã®å€¤ã‹ã‚‰å…ƒã®å€¤ã‚’å¼•ã„ãŸå€¤ã«å¯¾ã—ã¦ mask ã¨ã®è¦ç´ ç©ã‚’ã¨ã‚Šã€å¤‰æ›´å‰ã®å€¤ã«è¶³ã›ã°è‰¯ã„ã€‚ï¼ˆ $?$ ã¨ç¤ºã—ãŸã®ã¯ã©ã†ã§ã‚‚è‰¯ã„å€¤ï¼‰

    $$
    \begin{align}
    \begin{bmatrix}
    a & b\\
    c & d
    \end{bmatrix}
    &\leftarrow\begin{bmatrix}
    a & b\\
    c & d
    \end{bmatrix}
    +
    \begin{bmatrix}
    1 & 1\\
    0 & 0
    \end{bmatrix}
    \otimes
    \left(
    \begin{bmatrix}
    a' & b'\\
    ? & ?
    \end{bmatrix}
    - \begin{bmatrix}
    a & b\\
    c & d
    \end{bmatrix}
    \right)
    \\
    %
    %
    &\leftarrow\begin{bmatrix}
    a & b\\
    c & d
    \end{bmatrix}
    +
    \begin{bmatrix}
    a'-a & b'-b\\
    0 & 0
    \end{bmatrix}
    \\
    %
    %
    &\leftarrow\begin{bmatrix}
    a' & b'\\
    c & d
    \end{bmatrix}
    \end{align}
    $$


    ```python
    >>> import torch
    >>> x = torch.tensor([0.2, 0.4, 0.6, 0.8], requires_grad=True)
    >>> mask = x > 0.5
    >>> # x[mask] = 0.0 # Error
    >>> x = x + mask * (torch.zeros_like(x) - x)
    >>> print(x)

    tensor([0.2000, 0.4000, 0.0000, 0.0000], grad_fn=<AddBackward0>)
    ```

    ä¸Šã®ã‚³ãƒ¼ãƒ‰ã¯ã€ãƒ†ãƒ³ã‚½ãƒ«ã®å€¤ãŒ $0.5$ ã‚ˆã‚Šã‚‚å¤§ãã„å€¤ã‚’ã€$0$ ã«ç½®ãæ›ãˆãŸã„å ´åˆã®ä¾‹ã€‚

    ```python
    # indice -> mask
    indice = torch.tensor([2, 3], dtype=torch.long)
    mask = torch.zeros_like(x).bool().scatter_(0, indice, torch.ones_like(indice).bool())

    # slice -> mask
    mask = torch.zeros_like(x).bool()
    mask[2:] = True
    ```

    slice ã‚„ index ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€slice ã‚„ index ã‹ã‚‰ mask ã‚’ä½œæˆã™ã‚‹ã€‚



# in-place operation ã¨ã¯

> in-place operation ã¨ã¯ã€æ–°ã—ãã‚³ãƒ”ãƒ¼ã‚’ä½œã‚‹ã“ã¨ãªãã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­èº«ã‚’å¤‰æ›´ã™ã‚‹æ¼”ç®—ã®ã“ã¨ã§ã‚ã‚‹ã€‚in-place operation ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®æ¼”ç®—å­ã‚’ in-place operator ã¨ã„ã†ã€‚ï¼ˆæ„è¨³ï¼‰

https://www.tutorialspoint.com/inplace-operator-in-python

![](/images/in-place-error/compare.png)
*é€šå¸¸ã®ä»£å…¥æ¼”ç®— `x = x + 1` ã¨ã€in-place operator ã«ã‚ˆã‚‹æ¼”ç®— `x += 1` ã®æ¯”è¼ƒã€‚*

python ã§ã¯ã€`iadd()` ã‚„ `+=` ãªã©ã‚’ä½¿ã†ã¨ in-place operation ã«ãªã‚‹ã€‚

# PyTorch ã§ in-place operation

PyTorch ã§ in-place operation ã‚’ã™ã‚‹å ´åˆã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ–¹æ³•ãŒã‚ã‚‹ã€‚ï¼ˆä»–ã«ã‚‚ã‚ã‚‹ã‹ã‚‚ã€‚ï¼‰

1. `x.add_()` , `x.mul_()` ãªã©ã®é€šå¸¸ã®ãƒ¡ã‚½ãƒƒãƒ‰ã« `_` ã‚’ä»˜ã‘ãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
2. `x.data` ã‚’ä½¿ã†ã€‚ï¼ˆæ­£ç¢ºã«ã¯ in-place operation ã¨ã¯ç•°ãªã‚Šãã†ã€‚ï¼‰
3. indexã‚„maskã‚’ä½¿ç”¨ã™ã‚‹
4. `+=` , `*=` ãªã©ã‚’ä½¿ã†

## 1. `x.add_()` ã‚’ä½¿ã†
```python
>>> import torch
>>> x = torch.tensor([1.])
>>> x.add(1)
>>> print(x)
tensor([1.])
```
é€šå¸¸ã® `add` ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€`x` ã¯å¤‰æ›´ã•ã‚Œãªã„ã€‚
`x.add(1)` ã¨ã„ã†æ–°ã—ã„å¤‰æ•°ãŒç¢ºä¿ã•ã‚Œã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚

```python
>>> import torch
>>> x = torch.tensor([1.])
>>> x.add_(1) # in-place operation
>>> print(x)
tensor([2.])
```

`add_` ï¼ˆãƒã‚¤ãƒ•ãƒ³æœ‰ã‚Šï¼‰ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€`x` ã®å€¤ãŒå¤‰æ›´ã•ã‚Œã‚‹ã€‚

## 2. `x.data`ã‚’ä½¿ã†ï¼ˆæ­£ç¢ºã«ã¯in-placeã§ã¯ãªã•ãã†ï¼‰

:::message
`x.data` ã‚’ä½¿ã†æ–¹æ³•ã¯ PyTorchã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‹ã‚‰ã€æ­£ç¢ºã«ã¯ in-place operation ã§ã¯ãªã•ãã†ã§ã™ãŒã€ä¼¼ãŸã‚ˆã†ãªã“ã¨ãŒã§ãã‚‹ãŸã‚ã¾ã¨ã‚ã¾ã—ãŸã€‚
:::


```python
import torch

def my_add_one(input):
    input = input + 1

x = torch.tensor([1.])
my_add_one(x)

print(x)
# tensor([1.])
```

pythonã®é–¢æ•°ã®å¼•æ•°ã¯å‚ç…§æ¸¡ã—ãªã®ã§ã€`input` ã¨ `x` ã¯ `id` ãŒåŒã˜ã ãŒã€
`input = input + 1` ã®å·¦å´ã®å¤‰æ•° `input` ã¯ `id` ã¯ä¸Šã§è¿°ã¹ãŸ2ã¤ã¨ç•°ãªã‚‹ã€‚

```python
import torch

def my_add_one(input):
    input.data = input + 1

x = torch.tensor([1.])
my_add_one(x)

print(x)
# tensor([2.])
```

`input.data = input + 1` ã¨ã™ã‚‹ã¨ `x` ã®ä¸­èº«ãŒæ›¸ãæ›ãˆã‚‰ã‚Œã‚‹ã€‚

:::message
data field ã¯ä½¿ã†ã¹ãã§ãªãªã„ã¨è¨€åŠã•ã‚Œã¦ã„ã‚‹ã€‚ï¼ˆä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸ã‚’å‚è€ƒï¼‰
:::

https://discuss.pytorch.org/t/the-difference-between-torch-tensor-data-and-torch-tensor/25995
https://zenn.dev/chickenta2ta/articles/05763114fc0fe4

## 3. indexã‚„maskã‚’ä½¿ç”¨ã™ã‚‹

```python
>>> import torch
>>> x = torch.tensor([1, 2, 3])
>>> mask = x <= 2
>>> x[mask] = 10
>>> print(x)
tensor([10, 10,  3])
```

`x[0] = 2` ã‚„ `x[mask] = 2` ã®ã‚ˆã†ã«ã€indexã€sliceã€maskãªã©ã‚’ä½¿ç”¨ã—ã¦é¸æŠã—ãŸãƒ†ãƒ³ã‚½ãƒ«ã®ä¸€éƒ¨åˆ†ã«ä»£å…¥ã™ã‚‹ã¨ã€å€¤ãŒç½®ãæ›ãˆã‚‰ã‚Œã‚‹ã€‚

# in-place operation ã‚’å‹¾é…è¨ˆç®—ã§ã¯é¿ã‘ã‚‹

## ç™ºç”Ÿã™ã‚‹ã‚¨ãƒ©ãƒ¼

PyTorchã§ `requires_grad=True` ã¨ã—ãŸãƒ†ãƒ³ã‚½ãƒ«ã«å¯¾ã—ã¦ã€å‹¾é…è¨ˆç®—ã®ãŸã‚ã«ä½•ã‚‰ã‹ã® in-place ãªè¨ˆç®—å‡¦ç†ã‚’è¡Œã†ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã€‚

:::message alert
RuntimeError: a view of a leaf Variable that requires grad is being used in an in-place operation.
:::

ä¾‹ãˆã°ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¦ `requires_grad=True` ã¨ã—ãŸãƒ†ãƒ³ã‚½ãƒ«ã« in-place operation ã‚’ã™ã‚‹ã¨ã€ä¸Šè¿°ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã€‚

```python
import torch

x = torch.rand(20, requires_grad=True)

x.add_(1) # Error
x[1] = 0  # Error
x += 1    # Error

x.data = x + 1 # ã“ã‚Œã¯ErrorãŒã§ãªã„
```

PyTorchã®å…¬å¼ã«ã‚ˆã‚‹ã¨ã€å‹¾é…è¨ˆç®—ã®ãŸã‚ã®forwardã®è¨ˆç®—ãŒå£Šã‚Œã¦ã—ã¾ã†ãŸã‚ï¼ˆæ„è¨³ï¼‰in-place operation ã«ã‚ˆã‚‹ Error ãŒç™ºç”Ÿã™ã‚‹ã¨æ›¸ã„ã¦ã‚ã‚‹ã€‚ã¾ãŸã€ErrorãŒç™ºç”Ÿã—ãªã„å ´åˆã‚‚ã‚ã‚‹ã¨ã‚‚æ›¸ã‹ã‚Œã¦ã„ã‚‹ï¼ˆã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚ã€‚ã€‚ï¼‰ã€‚

https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd

## å¯¾å‡¦æ³•ï¼ˆå†æ²ï¼‰

- `x.add_()` ã¯ `x = x.add()`ã¨ã™ã‚‹ã€‚

- `x += 1` ã¯ `x = x + 1` ã¨ã™ã‚‹ã€‚

- mask ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€ä¾‹ãˆã°ä¸‹ã®å¼ã«ç¤ºã™ã‚ˆã†ã«$a$ ã¨ $b$ ã‚’æ–°ã—ã„å€¤ $a'$ ã¨ $b'$ ã§ç½®ãæ›ãˆãŸã„å ´åˆã€å¤‰æ›´å¾Œã®å€¤ã‹ã‚‰å…ƒã®å€¤ã‚’å¼•ã„ãŸå€¤ã«å¯¾ã—ã¦ mask ã¨ã®è¦ç´ ç©ã‚’ã¨ã‚Šã€å¤‰æ›´å‰ã®å€¤ã«è¶³ã›ã°è‰¯ã„ã€‚ï¼ˆ $?$ ã¨ç¤ºã—ãŸã®ã¯ã©ã†ã§ã‚‚è‰¯ã„å€¤ï¼‰

$$
\begin{align}
\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
&\leftarrow\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
+
\begin{bmatrix}
1 & 1\\
0 & 0
\end{bmatrix}
\otimes
\left(
\begin{bmatrix}
a' & b'\\
? & ?
\end{bmatrix}
- \begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
\right)
\\
%
%
&\leftarrow\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
+
\begin{bmatrix}
a'-a & b'-b\\
0 & 0
\end{bmatrix}
\\
%
%
&\leftarrow\begin{bmatrix}
a' & b'\\
c & d
\end{bmatrix}
\end{align}
$$


```python
>>> import torch
>>> x = torch.tensor([0.2, 0.4, 0.6, 0.8], requires_grad=True)
>>> mask = x > 0.5
>>> # x[mask] = 0.0 # Error
>>> x = x + mask * (torch.zeros_like(x) - x)
>>> print(x)

tensor([0.2000, 0.4000, 0.0000, 0.0000], grad_fn=<AddBackward0>)
```

ä¸Šã®ã‚³ãƒ¼ãƒ‰ã¯ã€ãƒ†ãƒ³ã‚½ãƒ«ã®å€¤ãŒ $0.5$ ã‚ˆã‚Šã‚‚å¤§ãã„å€¤ã‚’ã€$0$ ã«ç½®ãæ›ãˆãŸã„å ´åˆã®ä¾‹ã€‚

```python
# indice -> mask
indice = torch.tensor([2, 3], dtype=torch.long)
mask = torch.zeros_like(x).bool().scatter_(0, indice, torch.ones_like(indice).bool())

# slice -> mask
mask = torch.zeros_like(x).bool()
mask[2:] = True
```

slice ã‚„ index ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€slice ã‚„ index ã‹ã‚‰ mask ã‚’ä½œæˆã—ã€ä¸Šè¿°ã®æ–¹æ³•ã§å¯¾å‡¦ã™ã‚Œã°è‰¯ã„ã€‚


# å‚è€ƒæ–‡çŒ®
https://www.tutorialspoint.com/inplace-operator-in-python
https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd
https://discuss.pytorch.org/t/the-difference-between-torch-tensor-data-and-torch-tensor/25995
https://discuss.pytorch.org/t/what-is-in-place-operation/16244
https://www.kaggle.com/code/aleksandradeis/in-place-operations-in-pytorch
https://zenn.dev/chickenta2ta/articles/05763114fc0fe4
https://qiita.com/mathlive/items/3dcb46af2e2f0eca559a
